{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99396b2a-a7f9-4fa8-8974-87bbf06768b9",
   "metadata": {},
   "source": [
    "# Fraud Detection API: Complete Project Documentation\n",
    "### From Local Development to Production CI/CD Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a85fe2-c97e-4419-8c2d-9259878a78be",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "#### 1- Project Setup & Structure\n",
    "\n",
    "#### 2- Code Modularization\n",
    "\n",
    "#### 3- Local Testing (Flask API)\n",
    "\n",
    "#### 4- Docker Containerization\n",
    "\n",
    "#### 5- Kubernetes Deployment\n",
    "\n",
    "#### 6- CI/CD Pipeline Implementation\n",
    "\n",
    "#### 7- Troubleshooting Guide\n",
    "\n",
    "#### 8- Final Workflow Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1abf704-c38a-42d8-bb7d-8434d4f20039",
   "metadata": {},
   "source": [
    "### 1. Project Setup & Structure\n",
    "#### Initial Repository Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc5c9c-3ef5-4e52-8562-1dfbd8b26fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In powershell\n",
    "# Create project folder\n",
    "mkdir fraud-detection-cicd\n",
    "cd fraud-detection-cicd\n",
    "\n",
    "# Initialize Git\n",
    "git init\n",
    "\n",
    "# Create directory structure\n",
    "mkdir -p src/{config,preprocess,feature_engineer,train,predict,evaluate} tests deployments data models logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517d7a4-6792-4567-bc35-71c66c78c551",
   "metadata": {},
   "source": [
    "#### File Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34772b7e-201b-4752-957b-1cca17db7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud-detection-cicd/\n",
    "├── .github/workflows/\n",
    "│   ├── ci.yml\n",
    "│   └── cd.yml\n",
    "├── src/\n",
    "│   ├── config.py\n",
    "│   ├── preprocess.py\n",
    "│   ├── feature_engineer.py\n",
    "│   ├── train.py\n",
    "│   ├── predict.py\n",
    "│   ├── evaluate.py\n",
    "│   ├── app.py\n",
    "│   └── __init__.py\n",
    "├── tests/\n",
    "│   └── test_app.py\n",
    "├── deployments/\n",
    "│   ├── deployment.yaml\n",
    "│   └── service.yaml\n",
    "├── data/                  # Contains Fraud.csv (gitignored)\n",
    "├── Dockerfile\n",
    "├── requirements.txt\n",
    "└── .gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8da53-e361-42d5-aba6-398382a8e9d3",
   "metadata": {},
   "source": [
    "### 2. Code Modularization\n",
    "#### Key Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb806ad7-053d-4e75-94ff-0ed4ccb7c97e",
   "metadata": {},
   "source": [
    "#### 1- config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c268d-7bf3-4abd-999c-151a35c0908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Project setup\n",
    "PROJECT_ROOT = Path(__file__).parent.parent\n",
    "\n",
    "# Data configuration\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Try these data files in order (first found will be used)\n",
    "DATA_PATHS = [\n",
    "    DATA_DIR / 'sample_fraud.csv',  # Small sample for CI/testing (should be committed)\n",
    "    DATA_DIR / 'Fraud.csv',        # Full dataset for local development (gitignored)\n",
    "    Path(r'C:\\Projects\\fraud_detection\\data\\Fraud.csv')  # Fallback to original location\n",
    "]\n",
    "\n",
    "DATA_PATH = None\n",
    "for path in DATA_PATHS:\n",
    "    if path.exists():\n",
    "        DATA_PATH = path\n",
    "        break\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    print(\"\\nERROR: No suitable data file found. Please:\", file=sys.stderr)\n",
    "    print(\"1. Add 'sample_fraud.csv' to project's data/ folder for testing\", file=sys.stderr)\n",
    "    print(\"2. Or add 'Fraud.csv' to project's data/ folder for development\", file=sys.stderr)\n",
    "    print(f\"3. Or keep original at C:\\\\Projects\\\\fraud_detection\\\\data\\\\Fraud.csv\", file=sys.stderr)\n",
    "    print(\"\\nCreating empty data directory...\", file=sys.stderr)\n",
    "    (DATA_DIR / '.gitkeep').touch()\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"\\nℹ️ Using data file at: {DATA_PATH}\")\n",
    "\n",
    "# Model configuration\n",
    "MODEL_DIR = PROJECT_ROOT / 'models'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_DIR / 'fraud_model.joblib'\n",
    "\n",
    "# Logs configuration\n",
    "LOG_DIR = PROJECT_ROOT / 'logs'\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Data processing parameters\n",
    "N_ROWS = None  # Set to None to use all rows, or specify a number (e.g., 100000)\n",
    "AMOUNT_PERCENTILE = 0.95\n",
    "BALANCE_PERCENTILE = 0.9\n",
    "\n",
    "# Model training parameters\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.3\n",
    "SMOTE_RATIO = 0.3\n",
    "\n",
    "class AppConfig:\n",
    "    # API Settings\n",
    "    HOST = \"0.0.0.0\"\n",
    "    PORT = 8080\n",
    "    DEBUG = False\n",
    "    \n",
    "    # Model Monitoring\n",
    "    PREDICTION_LOGS = LOG_DIR / \"predictions.log\"\n",
    "    DRIFT_THRESHOLD = 0.15\n",
    "    \n",
    "    # Performance\n",
    "    MAX_REQUEST_SIZE = 1024 * 1024  # 1MB\n",
    "    \n",
    "    @classmethod\n",
    "    def validate_paths(cls):\n",
    "        \"\"\"Ensure all required directories exist\"\"\"\n",
    "        required_dirs = [\n",
    "            DATA_DIR,\n",
    "            MODEL_DIR,\n",
    "            LOG_DIR\n",
    "        ]\n",
    "        for directory in required_dirs:\n",
    "            directory.mkdir(exist_ok=True)\n",
    "            \n",
    "        if not DATA_PATH.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found at {DATA_PATH}\")\n",
    "\n",
    "# Initialize directories\n",
    "AppConfig.validate_paths()\n",
    "\n",
    "# Environment detection\n",
    "IS_CI = os.getenv('CI') == 'true'\n",
    "IS_TEST = os.getenv('TEST_MODE') == 'true'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\nCurrent Configuration:\")\n",
    "    print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "    print(f\"Data File: {DATA_PATH}\")\n",
    "    print(f\"Model Path: {MODEL_PATH}\")\n",
    "    print(f\"Log Directory: {LOG_DIR}\")\n",
    "    print(f\"CI Mode: {IS_CI}\")\n",
    "    print(f\"Test Mode: {IS_TEST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46607e-7e04-4505-a84a-9914e31d0fec",
   "metadata": {},
   "source": [
    "#### 2- Preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f0eb5-8f88-4b2a-b05c-97eb8ba3548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.config import AMOUNT_PERCENTILE, BALANCE_PERCENTILE\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Feature engineering pipeline\"\"\"\n",
    "    # Transaction features\n",
    "    amt_thresh = df[df['isFraud']==0]['amount'].quantile(AMOUNT_PERCENTILE)\n",
    "    bal_thresh = df[df['isFraud']==0]['oldbalanceOrg'].quantile(BALANCE_PERCENTILE)\n",
    "    \n",
    "    df['amount_to_balance'] = df['amount'] / (df['oldbalanceOrg'] + 1)\n",
    "    df['high_amount_flag'] = (df['amount'] > amt_thresh).astype(int)\n",
    "    df['balance_change_abs'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
    "    df['suspicious_withdrawal'] = (\n",
    "        (df['balance_change_abs'] > bal_thresh) & \n",
    "        (df['amount_to_balance'] > 0.5)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Time features\n",
    "    df['hour_of_day'] = ((df['step'] - 1) % 24) + 1\n",
    "    df['day_of_week'] = ((df['step'] - 1) // 24) % 7\n",
    "    df['is_weekend'] = ((df['day_of_week'] == 5) | (df['day_of_week'] == 6)).astype(int)\n",
    "    \n",
    "    # Categorical encoding\n",
    "    df = pd.get_dummies(df, columns=['type'], prefix='type')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50184e-7616-49d8-901b-fc7e3358ab31",
   "metadata": {},
   "source": [
    "#### 3- feature_engineer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b11b47-b2d8-48f0-ba72-bbe84d80f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from src.config import DATA_PATH, N_ROWS, TEST_SIZE, RANDOM_STATE, SMOTE_RATIO\n",
    "from src.feature_engineer import engineer_features\n",
    "\n",
    "def load_and_preprocess():\n",
    "    \"\"\"Load and preprocess data with proper error handling\"\"\"\n",
    "    try:\n",
    "        print(f\"Loading data from: {DATA_PATH}\")\n",
    "        df = pd.read_csv(DATA_PATH, nrows=N_ROWS)\n",
    "        \n",
    "        print(\"Applying feature engineering...\")\n",
    "        df = engineer_features(df)\n",
    "        \n",
    "        X = df.drop(['isFraud', 'nameOrig', 'nameDest'], axis=1)\n",
    "        y = df['isFraud']\n",
    "        \n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scaling\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        X_train_scaled = pt.fit_transform(X_train)\n",
    "        X_test_scaled = pt.transform(X_test)\n",
    "        \n",
    "        # Resampling\n",
    "        smote = SMOTE(sampling_strategy=SMOTE_RATIO, random_state=RANDOM_STATE)\n",
    "        X_res, y_res = smote.fit_resample(X_train_scaled, y_train)\n",
    "        \n",
    "        return X_res, y_res, X_test_scaled, y_test, pt\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9173ff7-7770-4657-baec-2bf1ba890960",
   "metadata": {},
   "source": [
    "#### 4- Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157696e9-9898-4343-bb1c-9842c891dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/train.py\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "from src.preprocess import load_and_preprocess\n",
    "from src.config import MODEL_PATH, RANDOM_STATE\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def train_model():\n",
    "    print(\"🚀 Starting model training...\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"🔍 Loading and preprocessing data...\")\n",
    "    X_res, y_res, X_test, y_test, pt = load_and_preprocess()\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"🤖 Initializing Random Forest model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        n_estimators=50,\n",
    "        max_depth=7,\n",
    "        max_samples=0.8,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"⚡ Training model...\")\n",
    "    model.fit(X_res, y_res)\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"🧪 Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "    \n",
    "    # Save ALL required artifacts\n",
    "    artifacts = {\n",
    "        'model': model,\n",
    "        'transformer': pt,\n",
    "        'feature_order': X_res.columns.tolist() if hasattr(X_res, 'columns') else [],\n",
    "        'metadata': {\n",
    "            'training_date': datetime.now().isoformat(),\n",
    "            'git_commit': os.getenv('GIT_COMMIT', 'unknown'),\n",
    "            'python_version': os.getenv('PYTHON_VERSION', 'unknown')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    dump(artifacts, MODEL_PATH)\n",
    "    print(f\"\\n✅ Model successfully saved to {MODEL_PATH}\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0dd47-8dad-4eb3-a2b2-1a1f71aea391",
   "metadata": {},
   "source": [
    "#### 5- Predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d6444-508e-4e86-910f-9cc1c6582c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/predict.py\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "from src.config import MODEL_PATH, AppConfig\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class FraudPredictor:\n",
    "    def __init__(self, test_mode=False):\n",
    "        self.test_mode = test_mode\n",
    "        self.model = None\n",
    "        self.pt = None\n",
    "        self.feature_order = []\n",
    "        self._init_logging()\n",
    "        \n",
    "        if not test_mode:\n",
    "            try:\n",
    "                self._load_model()\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Failed to load model: {str(e)}\")\n",
    "                # Fallback to test mode if model loading fails\n",
    "                self.test_mode = True\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load model artifacts with validation\"\"\"\n",
    "        if not os.path.exists(MODEL_PATH):\n",
    "            raise FileNotFoundError(f\"Model file not found at {MODEL_PATH}\")\n",
    "            \n",
    "        artifacts = load(MODEL_PATH)\n",
    "        \n",
    "        # Validate all required components exist\n",
    "        required_keys = {'model', 'transformer', 'feature_order'}\n",
    "        missing_keys = required_keys - set(artifacts.keys())\n",
    "        if missing_keys:\n",
    "            raise ValueError(f\"Missing required keys in model file: {missing_keys}\")\n",
    "            \n",
    "        self.model = artifacts['model']\n",
    "        self.pt = artifacts['transformer']\n",
    "        self.feature_order = artifacts.get('feature_order', [])\n",
    "        \n",
    "        print(\"✅ Model loaded successfully\")\n",
    "        print(f\"Model trained on: {artifacts.get('metadata', {}).get('training_date', 'unknown')}\")\n",
    "\n",
    "    def _init_logging(self):\n",
    "        \"\"\"Set up prediction logging\"\"\"\n",
    "        os.makedirs(os.path.dirname(AppConfig.PREDICTION_LOGS), exist_ok=True)\n",
    "        logging.basicConfig(\n",
    "            filename=AppConfig.PREDICTION_LOGS,\n",
    "            format='%(asctime)s - %(message)s',\n",
    "            level=logging.INFO\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def _validate_input(self, data: dict) -> None:\n",
    "        \"\"\"Ensure minimum required fields exist\"\"\"\n",
    "        required_fields = {\n",
    "            'amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "            'oldbalanceDest', 'newbalanceDest', 'step',\n",
    "            'isFlaggedFraud', 'type'\n",
    "        }\n",
    "        missing = required_fields - set(data.keys())\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required fields: {missing}\")\n",
    "\n",
    "    def log_prediction(self, data: dict, prediction: int):\n",
    "        \"\"\"Log prediction with context\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"input\": {k: v for k, v in data.items() if k != 'type'},\n",
    "            \"prediction\": prediction,\n",
    "            \"model_version\": \"1.0.0\",\n",
    "            \"test_mode\": self.test_mode\n",
    "        }\n",
    "        self.logger.info(json.dumps(log_entry))\n",
    "\n",
    "    def preprocess(self, transaction_data: dict):\n",
    "        \"\"\"Recreate features EXACTLY as during training\"\"\"\n",
    "        df = pd.DataFrame([transaction_data])\n",
    "        \n",
    "        # Feature engineering\n",
    "        df['amount_to_balance'] = df['amount'] / (df['oldbalanceOrg'] + 1)\n",
    "        df['high_amount_flag'] = (df['amount'] > 10000).astype(int)\n",
    "        df['balance_change_abs'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
    "        df['suspicious_withdrawal'] = (\n",
    "            (df['balance_change_abs'] > 5000) & \n",
    "            (df['amount_to_balance'] > 0.5)\n",
    "        ).astype(int)\n",
    "        \n",
    "        # Time features\n",
    "        df['hour_of_day'] = ((df['step'] - 1) % 24) + 1\n",
    "        df['day_of_week'] = ((df['step'] - 1) // 24) % 7\n",
    "        df['is_weekend'] = ((df['day_of_week'] == 5) | (df['day_of_week'] == 6)).astype(int)\n",
    "        \n",
    "        # Transaction type handling\n",
    "        valid_types = ['CASH_IN', 'CASH_OUT', 'DEBIT', 'PAYMENT', 'TRANSFER']\n",
    "        for t in valid_types:\n",
    "            df[f'type_{t}'] = 0\n",
    "        if 'type' in df and df['type'].iloc[0] in valid_types:\n",
    "            df[f'type_{df[\"type\"].iloc[0]}'] = 1\n",
    "            \n",
    "        # Verify feature match\n",
    "        missing = set(self.feature_order) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing features after processing: {missing}\")\n",
    "            \n",
    "        return self.pt.transform(df[self.feature_order])\n",
    "\n",
    "    def predict(self, transaction_data: dict) -> int:\n",
    "        \"\"\"Make a fraud prediction\"\"\"\n",
    "        if self.test_mode:\n",
    "            self.log_prediction(transaction_data, 0)\n",
    "            return 0  # Dummy prediction in test mode\n",
    "            \n",
    "        try:\n",
    "            self._validate_input(transaction_data)\n",
    "            processed = self.preprocess(transaction_data)\n",
    "            prediction = int(self.model.predict(processed)[0])\n",
    "            self.log_prediction(transaction_data, prediction)\n",
    "            return prediction\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Prediction failed: {str(e)}\")\n",
    "            raise RuntimeError(f\"Prediction failed: {str(e)}\")\n",
    "\n",
    "# For testing the predictor directly\n",
    "if __name__ == '__main__':\n",
    "    predictor = FraudPredictor(test_mode=True)\n",
    "    test_data = {\n",
    "        \"amount\": 100,\n",
    "        \"oldbalanceOrg\": 1000,\n",
    "        \"newbalanceOrig\": 900,\n",
    "        \"oldbalanceDest\": 500,\n",
    "        \"newbalanceDest\": 600,\n",
    "        \"step\": 1,\n",
    "        \"isFlaggedFraud\": 0,\n",
    "        \"type\": \"TRANSFER\"\n",
    "    }\n",
    "    print(\"Test prediction:\", predictor.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ceafc-dc3a-4a0a-8216-f21f31e9cd48",
   "metadata": {},
   "source": [
    "#### 6- Evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2c483-ea5d-4dd4-b85d-3224f9e03af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe99ce4-2d85-457c-85ac-b159f0e91400",
   "metadata": {},
   "source": [
    "#### Now create empty __init__.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173bffb-12a1-48a3-a551-ed57b8817104",
   "metadata": {},
   "source": [
    "#### setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b740f-a0e4-4a9d-ab81-d4960416caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name=\"fraud-detection\",\n",
    "    version=\"0.1\",\n",
    "    packages=find_packages(include=['src*']), \n",
    "    install_requires=[\n",
    "        'pandas>=1.5.0',\n",
    "        'scikit-learn>=1.2.0',\n",
    "        'Flask>=2.0.0',\n",
    "        'joblib>=1.0.0',\n",
    "        'imbalanced-learn>=0.10.0',\n",
    "        'scipy>=1.7.0',\n",
    "        'numpy>=1.21.0',\n",
    "        'waitress>=2.1.0'\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76da64-6949-4e75-b8b3-630142c68c74",
   "metadata": {},
   "source": [
    "### 3. Local Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab323f-625d-43b6-adc1-d4b0001cd154",
   "metadata": {},
   "source": [
    "#### Flask API (app.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d1a777-1c4a-4862-9057-e97a17ce530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from src.predict import FraudPredictor\n",
    "from datetime import datetime\n",
    "from src.config import AppConfig\n",
    "import os\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize predictor with explicit test mode in CI\n",
    "is_ci = os.getenv('GITHUB_ACTIONS') == 'true'\n",
    "predictor = FraudPredictor(test_mode=is_ci or not os.path.exists('models/fraud_model.joblib'))\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No JSON provided\"}), 400\n",
    "            \n",
    "        # Validate required fields\n",
    "        required_fields = {\n",
    "            'amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "            'oldbalanceDest', 'newbalanceDest', 'step',\n",
    "            'isFlaggedFraud', 'type'\n",
    "        }\n",
    "        missing = required_fields - set(data.keys())\n",
    "        if missing:\n",
    "            return jsonify({\"error\": f\"Missing required fields: {missing}\", \"status\": \"input_error\"}), 400\n",
    "\n",
    "        prediction = predictor.predict(data)\n",
    "        \n",
    "        return jsonify({\n",
    "            \"fraud_prediction\": prediction,\n",
    "            \"model_info\": {\n",
    "                \"version\": \"1.0.0\",\n",
    "                \"type\": \"RandomForest\",\n",
    "                \"test_mode\": predictor.test_mode\n",
    "            },\n",
    "            \"status\": \"success\"\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e), \"status\": \"server_error\"}), 500\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model_loaded\": not predictor.test_mode\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=AppConfig.HOST, port=AppConfig.PORT, debug=AppConfig.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133f0c6-84b6-4283-a72c-e6b21ac3507d",
   "metadata": {},
   "source": [
    "#### Test Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ff7ce-7712-4f03-be0f-ec04ab41807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run the Training\n",
    "python src\\train.py\n",
    "\n",
    "# Run Flask\n",
    "python src/app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d4e10-a455-4be2-86a8-a61db026c127",
   "metadata": {},
   "source": [
    "#### Now let's put this Model to Test! Copy the features in exact order and give it values. Now in another terminal execute the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac761ca-b768-4407-a5eb-7709d7b216f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST http://localhost:8080/predict ^\n",
    "-H \"Content-Type: application/json\" ^\n",
    "-d \"{^\n",
    "\\\"step\\\": 1,^\n",
    "\\\"amount\\\": 9839.64,^\n",
    "\\\"oldbalanceOrg\\\": 170136.0,^\n",
    "\\\"newbalanceOrig\\\": 160296.36,^\n",
    "\\\"oldbalanceDest\\\": 0.0,^\n",
    "\\\"newbalanceDest\\\": 9839.64,^\n",
    "\\\"isFlaggedFraud\\\": 0,^\n",
    "\\\"type\\\": \\\"CASH_OUT\\\",^\n",
    "\\\"amount_to_balance\\\": 0.0578,^\n",
    "\\\"high_amount_flag\\\": 1,^\n",
    "\\\"balance_change_abs\\\": 9839.64,^\n",
    "\\\"suspicious_withdrawal\\\": 0,^\n",
    "\\\"hour_of_day\\\": 1,^\n",
    "\\\"day_of_week\\\": 0,^\n",
    "\\\"is_weekend\\\": 0^\n",
    "}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148448e-29ff-4d52-8752-4353d11d97e6",
   "metadata": {},
   "source": [
    "#### Create tests/test_app.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac991f-b759-438d-8c1d-e54dfe2a3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from src.app import app\n",
    "import os\n",
    "import json\n",
    "\n",
    "class TestAPI(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        app.config['TESTING'] = True\n",
    "        self.client = app.test_client()\n",
    "        self.test_data = {\n",
    "            \"amount\": 100,\n",
    "            \"oldbalanceOrg\": 1000,\n",
    "            \"newbalanceOrig\": 900,\n",
    "            \"oldbalanceDest\": 500,\n",
    "            \"newbalanceDest\": 600,\n",
    "            \"step\": 1,\n",
    "            \"isFlaggedFraud\": 0,\n",
    "            \"type\": \"TRANSFER\"\n",
    "        }\n",
    "    \n",
    "    def test_health_check(self):\n",
    "        response = self.client.get('/health')\n",
    "        self.assertEqual(response.status_code, 200)\n",
    "        self.assertEqual(response.json['status'], 'healthy')\n",
    "        # Don't assert model_loaded since it depends on environment\n",
    "\n",
    "    def test_predict_endpoint(self):\n",
    "        response = self.client.post('/predict', json=self.test_data)\n",
    "        self.assertEqual(response.status_code, 200)\n",
    "        self.assertIn('fraud_prediction', response.json)\n",
    "        # Accept either test mode or not\n",
    "        self.assertIn(response.json['model_info']['test_mode'], [True, False])\n",
    "\n",
    "    def test_invalid_input(self):\n",
    "        invalid_data = self.test_data.copy()\n",
    "        invalid_data.pop('amount')\n",
    "        response = self.client.post('/predict', json=invalid_data)\n",
    "        self.assertIn(response.status_code, [400, 500])  # Accept either error code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa086d5d-7a1f-4472-824f-651c0b7042c0",
   "metadata": {},
   "source": [
    "### 4. Docker Containerization\n",
    "#### Dockerfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab33e-1bd9-49bb-88f5-d96763e7dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    gcc \\\n",
    "    python3-dev \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy requirements first\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application code\n",
    "COPY src/ ./src/\n",
    "COPY app.py .\n",
    "COPY config.py .\n",
    "\n",
    "# Create directories\n",
    "RUN mkdir -p /app/models /app/logs\n",
    "\n",
    "# Environment variables\n",
    "ENV MODEL_PATH=/app/models/fraud_model.joblib\n",
    "ENV FLASK_APP=app.py\n",
    "ENV PYTHONPATH=/app\n",
    "\n",
    "# Copy model file (if exists)\n",
    "COPY models/fraud_model.joblib /app/models/ || echo \"No model file found, will run in test mode\"\n",
    "\n",
    "EXPOSE 8080\n",
    "CMD [\"python\", \"-c\", \"from waitress import serve; from app import app; serve(app, host='0.0.0.0', port=8080)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f3302-8dab-425f-8b76-f716185a570f",
   "metadata": {},
   "source": [
    "#### Create requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9446d-cd41-47f4-bf8a-a798a77669c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas>=1.5.0\n",
    "scikit-learn>=1.2.0\n",
    "Flask>=2.0.0\n",
    "joblib>=1.0.0\n",
    "imbalanced-learn>=0.10.0\n",
    "scipy>=1.7.0\n",
    "numpy>=1.21.0\n",
    "waitress>=2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc1679-c89b-4921-af62-1f013957afce",
   "metadata": {},
   "source": [
    "#### Create Your serve.py file serves two main purposes:\n",
    "\n",
    "#### 1- Replaces Flask's Development Server\n",
    "\n",
    "##### Flask's built-in server (app.run()) is not suitable for production (slow, insecure, single-threaded).\n",
    "\n",
    "##### waitress is a production-ready WSGI server that handles multiple requests efficiently.\n",
    "\n",
    "#### 2- Standardizes the Startup Process\n",
    "\n",
    "##### Provides a consistent entry point for Docker to launch your app.\n",
    "\n",
    "##### Ensures directories exist and logging is configured before starting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f3334-4c31-4c23-b807-fe479d557c3b",
   "metadata": {},
   "source": [
    "#### serve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c38c3-f99d-4d4f-8ad1-9bf00ec33149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waitress import serve\n",
    "from app import app  # Import your Flask app\n",
    "from src.config import PROJECT_ROOT\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Production configuration\n",
    "MODEL_DIR = PROJECT_ROOT / 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('waitress')\n",
    "logger.info('Starting server...')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(f\"🚀 Serving fraud detection API on http://localhost:8080\")\n",
    "    serve(app, host='0.0.0.0', port=8080)  # Production-ready server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3494647-b615-4a04-8c94-ce2a905c0c23",
   "metadata": {},
   "source": [
    "#### Build & Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e1e0fb-63fe-423a-beb8-77d5e13b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker build -t fraud-detection .\n",
    "docker run -p 8080:8080 fraud-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f7dfa-8474-41fe-a917-5b5938e78e28",
   "metadata": {},
   "source": [
    "#### Test the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05989df-d7b0-4bc5-9425-9d4ea06cdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST http://localhost:8080/predict ^\n",
    "-H \"Content-Type: application/json\" ^\n",
    "-d \"{\\\"step\\\":1,\\\"amount\\\":1000,\\\"oldbalanceOrg\\\":5000,\\\"newbalanceOrig\\\":4000,\\\"oldbalanceDest\\\":0,\\\"newbalanceDest\\\":1000,\\\"isFlaggedFraud\\\":0,\\\"amount_to_balance\\\":0.2,\\\"high_amount_flag\\\":0,\\\"balance_change_abs\\\":1000,\\\"suspicious_withdrawal\\\":0,\\\"hour_of_day\\\":10,\\\"day_of_week\\\":2,\\\"is_weekend\\\":0,\\\"type\\\":\\\"CASH_OUT\\\",\\\"type_CASH_IN\\\":0,\\\"type_CASH_OUT\\\":1,\\\"type_DEBIT\\\":0,\\\"type_PAYMENT\\\":0,\\\"type_TRANSFER\\\":0}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31878e63-45d4-47d0-b62a-1684745c5681",
   "metadata": {},
   "source": [
    "### 5. Kubernetes Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a08c7-10f0-4eb1-bf14-3c628368fb3f",
   "metadata": {},
   "source": [
    "#### deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75cdbc5-1d59-4ab7-a84f-acf35f976d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: fraud-detection-api\n",
    "spec:\n",
    "  replicas: 2\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: fraud-detection\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: fraud-detection\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: fraud-api\n",
    "        image: moeyahya/fraud-detection-api:latest\n",
    "        imagePullPolicy: Always\n",
    "        ports:\n",
    "        - containerPort: 8080\n",
    "        env:\n",
    "        - name: MODEL_PATH\n",
    "          value: \"/app/models/fraud_model.joblib\"\n",
    "        volumeMounts:\n",
    "        - mountPath: /app/models\n",
    "          name: models-volume\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: \"100m\"\n",
    "            memory: \"128Mi\"\n",
    "          limits:\n",
    "            cpu: \"500m\"\n",
    "            memory: \"512Mi\"\n",
    "      volumes:\n",
    "      - name: models-volume\n",
    "        emptyDir: {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eac27e-33fe-41a1-b9ac-2ff3743a7e8a",
   "metadata": {},
   "source": [
    "#### service.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc43dbf-b2fa-47f2-b113-48e0f0971cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: fraud-detection-service\n",
    "spec:\n",
    "  type: NodePort\n",
    "  selector:\n",
    "    app: fraud-detection\n",
    "  ports:\n",
    "    - protocol: TCP\n",
    "      port: 80\n",
    "      targetPort: 8080\n",
    "      nodePort: 30080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b9500-718e-4a6a-a20f-e028fa838fca",
   "metadata": {},
   "source": [
    "#### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be76975-b536-4226-9d2c-e186e90b557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apply Configurations\n",
    "kubectl apply -f deployments/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339b7b2-5c13-49fc-8973-e728c5da8022",
   "metadata": {},
   "source": [
    "### 6. CI/CD Pipeline\n",
    "#### CI Pipeline (ci.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a16875-c9bf-4737-8898-8d2f04785c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "name: Continuous Integration\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ \"main\" ]\n",
    "  pull_request:\n",
    "    branches: [ \"main\" ]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    timeout-minutes: 15\n",
    "\n",
    "    steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Set up Python 3.10\n",
    "      uses: actions/setup-python@v4\n",
    "      with:\n",
    "        python-version: '3.10'\n",
    "        cache: 'pip'\n",
    "\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install pandas pytest pytest-cov joblib scikit-learn imbalanced-learn\n",
    "        pip install -e .\n",
    "\n",
    "    - name: Create sample data\n",
    "      run: |\n",
    "        mkdir -p data\n",
    "        python -c \"\n",
    "        import pandas as pd;\n",
    "        df = pd.DataFrame({\n",
    "            'step': [1, 2, 3, 4, 5],\n",
    "            'type': ['CASH_IN', 'CASH_OUT', 'PAYMENT', 'TRANSFER', 'DEBIT'],\n",
    "            'amount': [100, 200, 300, 400, 500],\n",
    "            'nameOrig': ['A', 'B', 'C', 'D', 'E'],\n",
    "            'oldbalanceOrg': [1000, 2000, 3000, 4000, 5000],\n",
    "            'newbalanceOrig': [900, 1900, 2900, 3900, 4900],\n",
    "            'nameDest': ['X', 'Y', 'Z', 'W', 'V'],\n",
    "            'oldbalanceDest': [500, 600, 700, 800, 900],\n",
    "            'newbalanceDest': [600, 700, 800, 900, 1000],\n",
    "            'isFraud': [0, 1, 0, 1, 0],\n",
    "            'isFlaggedFraud': [0, 0, 0, 0, 0]\n",
    "        });\n",
    "        df.to_csv('data/sample_fraud.csv', index=False)\n",
    "        \"\n",
    "\n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        PYTHONPATH=$PYTHONPATH:$GITHUB_WORKSPACE pytest tests/ \\\n",
    "          --cov=src \\\n",
    "          --cov-report=xml \\\n",
    "          --cov-report=term-missing \\\n",
    "          -v\n",
    "\n",
    "    - name: Upload coverage\n",
    "      uses: codecov/codecov-action@v3\n",
    "      with:\n",
    "        token: ${{ secrets.CODECOV_TOKEN }}\n",
    "        files: coverage.xml\n",
    "        flags: unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f91ff-6bb8-439e-b904-1b92304bd2b1",
   "metadata": {},
   "source": [
    "#### CD Pipeline (cd.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f79e6d-9030-4777-bfa6-b9f1ec10fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name: Continuous Deployment\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ \"main\" ]\n",
    "    paths:\n",
    "      - 'src/**'\n",
    "      - 'Dockerfile'\n",
    "      - 'requirements.txt'\n",
    "      - 'deployments/**'\n",
    "\n",
    "env:\n",
    "  DOCKER_IMAGE: moeyahya/fraud-detection-api\n",
    "  DOCKER_TAG: latest\n",
    "\n",
    "jobs:\n",
    "  build-and-deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "    environment: production\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Set up Python\n",
    "      uses: actions/setup-python@v4\n",
    "      with:\n",
    "        python-version: '3.10'\n",
    "\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install -r requirements.txt\n",
    "\n",
    "    - name: Log in to Docker Hub\n",
    "      uses: docker/login-action@v3\n",
    "      with:\n",
    "        username: ${{ secrets.DOCKER_HUB_USERNAME }}\n",
    "        password: ${{ secrets.DOCKER_HUB_TOKEN }}\n",
    "\n",
    "    - name: Build and push\n",
    "      uses: docker/build-push-action@v5\n",
    "      with:\n",
    "        context: .\n",
    "        push: true\n",
    "        tags: ${{ env.DOCKER_IMAGE }}:${{ env.DOCKER_TAG }}\n",
    "        cache-from: type=gha\n",
    "        cache-to: type=gha,mode=max\n",
    "\n",
    "    - name: Set up Kubernetes\n",
    "      id: setup-kube\n",
    "      uses: azure/setup-kubectl@v3\n",
    "      continue-on-error: true\n",
    "\n",
    "    - name: Deploy to Kubernetes\n",
    "      if: steps.setup-kube.outcome == 'success' && env.KUBE_CONFIG != ''\n",
    "      env:\n",
    "        KUBE_CONFIG: ${{ secrets.KUBE_CONFIG }}\n",
    "      run: |\n",
    "        if [ -z \"$KUBE_CONFIG\" ]; then\n",
    "          echo \"No KUBE_CONFIG set, skipping deployment\"\n",
    "          exit 0\n",
    "        fi\n",
    "        \n",
    "        mkdir -p ~/.kube\n",
    "        echo \"$KUBE_CONFIG\" > ~/.kube/config\n",
    "        chmod 600 ~/.kube/config\n",
    "        \n",
    "        kubectl apply -f deployments/deployment.yaml\n",
    "        kubectl apply -f deployments/service.yaml\n",
    "        \n",
    "        kubectl rollout status deployment/fraud-detection-api\n",
    "        kubectl get pods,svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce10c63-3bd2-421f-9728-19e340d52a63",
   "metadata": {},
   "source": [
    "#### Create a .gitignore File (Could becreated at very early stages as we know this will be needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b551d-5078-492a-9f1b-79b37bbdaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "data/\n",
    "!data/.gitkeep\n",
    "\n",
    "# Byte-compiled files\n",
    "__pycache__/\n",
    "*.pyc\n",
    "\n",
    "# Logs\n",
    "logs/\n",
    "\n",
    "# Models\n",
    "models/\n",
    "\n",
    "# Environment files\n",
    ".env\n",
    ".venv\n",
    "venv/\n",
    "\n",
    "# Editor files\n",
    ".idea/\n",
    ".vscode/\n",
    "*.swp\n",
    "*.swo\n",
    "\n",
    "# System files\n",
    ".DS_Storedata/\n",
    "data/\n",
    "models/\n",
    "logs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08cfb9-26f1-40ee-85cd-b5dbc07c8fba",
   "metadata": {},
   "source": [
    "#### Set Up GitHub Secrets\n",
    "For the CD pipeline to work, you need to set up secrets in your GitHub repository:\n",
    "\n",
    "1- Go to your GitHub repository\n",
    "\n",
    "2- Click on \"Settings\" > \"Secrets and variables\" > \"Actions\"\n",
    "\n",
    "3- Click \"New repository secret\"\n",
    "\n",
    "Add these secrets:\n",
    "\n",
    "-DOCKER_HUB_USERNAME: Your Docker Hub username\n",
    "\n",
    "-DOCKER_HUB_TOKEN: Your Docker Hub access token (create in Docker Hub account settings)\n",
    "\n",
    "-KUBE_CONFIG: Your Kubernetes config file content (get this from ~/.kube/config on your local machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aaecce-4cf9-4f77-8ce7-f6215220f548",
   "metadata": {},
   "source": [
    "#### Commit and Push Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a48c5d-95a9-4710-87ad-3240d734e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "git add .\n",
    "git commit -m \"CI/CD workflows\"\n",
    "git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be013899-efd7-4237-a3e8-94575c876184",
   "metadata": {},
   "source": [
    "#### Monitor the Workflows\n",
    "1- Go to your GitHub repository\n",
    "\n",
    "2- Click on the \"Actions\" tab\n",
    "\n",
    "3- You should see your workflows running\n",
    "\n",
    "4- Click on each workflow to see detailed logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac379245-a580-4c52-9122-0e506d0d1461",
   "metadata": {},
   "source": [
    "#### Verify Deployment\n",
    "Once the CD pipeline completes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd229a-fdd3-49ad-9870-ac666206da26",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- Check your Kubernetes cluster:\n",
    "\n",
    "powershell\n",
    "kubectl get pods\n",
    "kubectl get services\n",
    "\n",
    "PS C:\\Projects\\fraud-detection-cicd> kubectl get pods\n",
    "NAME                                   READY   STATUS    RESTARTS   AGE\n",
    "fraud-detection-api-7875d449bb-xl6tz   1/1     Running   0          2d3h\n",
    "test-api-5f8664f4cb-9nqd7              1/1     Running   0          2d6h\n",
    "\n",
    "PS C:\\Projects\\fraud-detection-cicd> kubectl get services\n",
    "NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\n",
    "fraud-detection-service   NodePort    10.102.207.162   <none>        80:30080/TCP   3d\n",
    "kubernetes                ClusterIP   10.96.0.1        <none>        443/TCP        3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384cc1-0913-46e2-8369-eb1c6fee4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "2- Find the external IP (if using LoadBalancer) or port-forward to access your service:\n",
    "\n",
    "powershell\n",
    "kubectl port-forward service/fraud-detection-service 5000:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724dbeac-f8b5-4eb3-9d9c-594bd09c3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "3- Test the API endpoint:\n",
    "\n",
    "powershell\n",
    "curl http://localhost:5000/health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9ed9e-05ad-4782-a215-75cb0ba9f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI Pipeline:\n",
    "\n",
    "✅ Runs on every push\n",
    "\n",
    "✅ Creates sample data\n",
    "\n",
    "✅ Runs tests\n",
    "\n",
    "✅ Uploads coverage\n",
    "\n",
    "CD Pipeline:\n",
    "\n",
    "✅ Builds Docker image only when relevant paths change (src/, Dockerfile, etc.)\n",
    "\n",
    "✅ Pushes to Docker Hub\n",
    "\n",
    "✅ Conditionally deploys to Kubernetes (if KUBE_CONFIG exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243151b-7e21-4974-ba13-b0d000af73cb",
   "metadata": {},
   "source": [
    "### 8. Workflow Diagrams\n",
    "#### Local Development Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec4712-5c19-4e94-955b-c2e312d208fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Code] → [Test Locally] → [Dockerize] → [Kubernetes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b0eda-d53c-4a68-8ff0-c289ddd57f34",
   "metadata": {},
   "source": [
    "#### CI/CD Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9efe8f5-3d38-45bf-8b3d-c020a923a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Git Push] → [CI Tests] → [CD Build] → [Kubernetes Rollout]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2388d-9303-46e8-a776-d71596c7ef4e",
   "metadata": {},
   "source": [
    "## AWS CI/CD Pipeline for Fraud Detection API\n",
    "### Using Free-Tier Eligible Services\n",
    "#### Architecture: GitHub → AWS CodePipeline → ECS Fargate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49f508-a06a-4897-8f7f-71b563ef4262",
   "metadata": {},
   "source": [
    "### 1. Prerequisites\n",
    "#### - AWS Account (Free Tier eligible)\n",
    "\n",
    "#### - AWS CLI configured (aws configure)\n",
    "\n",
    "#### - Docker installed locally\n",
    "\n",
    "#### - GitHub repository with your code\n",
    "\n",
    "#### - ECR repository created (see Step 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e29e8-90f6-49f9-b993-754d61b55903",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e5a620-829a-4987-869c-16d258cd3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Projects\\fraud-detection-cicd\\\n",
    "├── .github/\n",
    "│   └── workflows/          # GitHub Actions (optional)\n",
    "├── deployments/            # Kubernetes files\n",
    "├── src/                    # Python code\n",
    "├── tests/                  # Test scripts\n",
    "├── Dockerfile              # Docker configuration\n",
    "├── buildspec.yml    \n",
    "└── requirements.txt        # Python dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b73a09-5143-4e99-b178-a9e5a2a13d2e",
   "metadata": {},
   "source": [
    "#### Create Essential Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6f6c0-3da0-4eb9-ac7d-45767d61781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Projects\\fraud-detection-cicd\\buildspec.yml\n",
    "version: 0.2\n",
    "phases:\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo \"Logging in to ECR...\"\n",
    "      - aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com\n",
    "  build:\n",
    "    commands:\n",
    "      - docker build -t $ECR_REPOSITORY:latest .\n",
    "      - docker tag $ECR_REPOSITORY:latest $ECR_REPOSITORY:$IMAGE_TAG\n",
    "  post_build:\n",
    "    commands:\n",
    "      - docker push $ECR_REPOSITORY:$IMAGE_TAG\n",
    "      - printf '[{\"name\":\"fraud-detection-api\",\"imageUri\":\"%s\"}]' $ECR_REPOSITORY:$IMAGE_TAG > imagedefinitions.json\n",
    "artifacts:\n",
    "  files:\n",
    "    - imagedefinitions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dfa34-c525-4e40-ba29-881d0c472f77",
   "metadata": {},
   "source": [
    "### 2. Set Up AWS Infrastructure\n",
    "#### 2.1 Create ECR Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7216fe-64e2-4289-8488-d3c1546e5d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws ecr create-repository --repository-name fraud-detection-api --region ca-central-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edd47f-eed0-47a4-a0dd-e86ac56675f3",
   "metadata": {},
   "source": [
    "#### 2.2 Create ECS Cluster (Fargate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17713e34-60f2-4b62-9ecd-4ee66d43b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws ecs create-cluster --cluster-name fraud-api-cluster --region ca-central-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf392d3-69b5-487e-a06b-a0a8870aeca4",
   "metadata": {},
   "source": [
    "#### 2.3 Create S3 Bucket for Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb114f6b-c64c-47b8-bd31-930dc1f7f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "$BUCKET_NAME = \"fraud-detection-artifacts-\" + (Get-Date -Format \"yyyyMMddHHmmss\")\n",
    "aws s3api create-bucket --bucket $BUCKET_NAME --region ca-central-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59614d-0f53-4248-ad74-8fa2bfe449dd",
   "metadata": {},
   "source": [
    "### 3. Configure CodeBuild\n",
    "#### 3.1 Create codebuild-role.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe06ef8-63ce-4d1c-a01c-4ce12da59ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "// C:\\Projects\\fraud-detection-cicd\\deployments\\codebuild-role.json\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"codebuild.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb6466-640c-46f2-b1b4-4fbc72398a79",
   "metadata": {},
   "source": [
    "#### 3.2 Create IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144abd29-1122-4417-b2a0-4939f60e3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws iam create-role --role-name CodeBuildServiceRole --assume-role-policy-document file://deployments/codebuild-role.json\n",
    "aws iam attach-role-policy --role-name CodeBuildServiceRole --policy-arn arn:aws:iam::aws:policy/AdministratorAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3c1348-dc44-47d8-8a8c-e5a613b8d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## or use this \n",
    "aws iam create-role `\n",
    "  --role-name ecsTaskExecutionRole `\n",
    "  --assume-role-policy-document '{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": { \"Service\": \"ecs-tasks.amazonaws.com\" },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }]\n",
    "  }'\n",
    "\n",
    "aws iam attach-role-policy `\n",
    "  --role-name ecsTaskExecutionRole `\n",
    "  --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc34f1d-55f3-41e5-af3d-33c8ee2d3a15",
   "metadata": {},
   "source": [
    "#### 3.3 Create CodeBuild Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c83da-4728-4f7c-b1c9-3ca44e23debb",
   "metadata": {},
   "source": [
    "#### codebuild-project.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb205463-3377-47d0-bf45-8c626ccd5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"name\": \"fraud-detection-build\",\n",
    "  \"source\": { \"type\": \"CODEPIPELINE\" },\n",
    "  \"artifacts\": { \"type\": \"CODEPIPELINE\" },\n",
    "  \"environment\": {\n",
    "    \"type\": \"LINUX_CONTAINER\",\n",
    "    \"image\": \"aws/codebuild/amazonlinux2-x86_64-standard:4.0\",\n",
    "    \"computeType\": \"BUILD_GENERAL1_SMALL\",\n",
    "    \"privilegedMode\": true,\n",
    "    \"environmentVariables\": [\n",
    "      { \"name\": \"AWS_ACCOUNT_ID\", \"value\": \"311410995726\" },\n",
    "      { \"name\": \"AWS_REGION\", \"value\": \"ca-central-1\" }\n",
    "    ]\n",
    "  },\n",
    "  \"serviceRole\": \"CodeBuildFraudDetectionRole\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43d0b9-b5cd-45e7-8c42-af757310a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws codebuild create-project --cli-input-json file://deployments/codebuild-project.json --region ca-central-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c6657-f1a2-4651-98cd-8bd4cc76d466",
   "metadata": {},
   "source": [
    "### 4. Create CodePipeline\n",
    "#### 4.1 Create pipeline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65705994-d583-4dc6-8d18-64a9bc1a70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "// C:\\Projects\\fraud-detection-cicd\\deployments\\pipeline.json\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"fraud-detection-pipeline\",\n",
    "    \"roleArn\": \"arn:aws:iam::YOUR_ACCOUNT_ID:role/CodePipelineServiceRole\",\n",
    "    \"artifactStore\": {\n",
    "      \"type\": \"S3\",\n",
    "      \"location\": \"YOUR_BUCKET_NAME\"\n",
    "    },\n",
    "    \"stages\": [\n",
    "      {\n",
    "        \"name\": \"Source\",\n",
    "        \"actions\": [\n",
    "          {\n",
    "            \"name\": \"GitHub_Source\",\n",
    "            \"actionTypeId\": {\n",
    "              \"category\": \"Source\",\n",
    "              \"owner\": \"ThirdParty\",\n",
    "              \"provider\": \"GitHub\",\n",
    "              \"version\": \"1\"\n",
    "            },\n",
    "            \"configuration\": {\n",
    "              \"Owner\": \"moeyahya\",\n",
    "              \"Repo\": \"fraud-detection-ml-api-aws-cicd\",\n",
    "              \"Branch\": \"main\",\n",
    "              \"OAuthToken\": \"YOUR_GITHUB_TOKEN\"\n",
    "            },\n",
    "            \"outputArtifacts\": [\n",
    "              {\n",
    "                \"name\": \"SourceOutput\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"Build\",\n",
    "        \"actions\": [\n",
    "          {\n",
    "            \"name\": \"Build\",\n",
    "            \"actionTypeId\": {\n",
    "              \"category\": \"Build\",\n",
    "              \"owner\": \"AWS\",\n",
    "              \"provider\": \"CodeBuild\",\n",
    "              \"version\": \"1\"\n",
    "            },\n",
    "            \"configuration\": {\n",
    "              \"ProjectName\": \"fraud-detection-build\"\n",
    "            },\n",
    "            \"inputArtifacts\": [\n",
    "              {\n",
    "                \"name\": \"SourceOutput\"\n",
    "              }\n",
    "            ],\n",
    "            \"outputArtifacts\": [\n",
    "              {\n",
    "                \"name\": \"BuildOutput\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"Deploy\",\n",
    "        \"actions\": [\n",
    "          {\n",
    "            \"name\": \"Deploy\",\n",
    "            \"actionTypeId\": {\n",
    "              \"category\": \"Deploy\",\n",
    "              \"owner\": \"AWS\",\n",
    "              \"provider\": \"ECS\",\n",
    "              \"version\": \"1\"\n",
    "            },\n",
    "            \"configuration\": {\n",
    "              \"ClusterName\": \"fraud-api-cluster\",\n",
    "              \"ServiceName\": \"fraud-detection-service\",\n",
    "              \"FileName\": \"imagedefinitions.json\"\n",
    "            },\n",
    "            \"inputArtifacts\": [\n",
    "              {\n",
    "                \"name\": \"BuildOutput\"\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a7a7a-7655-4e7d-bee4-676267963976",
   "metadata": {},
   "source": [
    "#### 4.2 Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab0200-358d-4792-a3ca-72a2ed2fc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws codepipeline create-pipeline --cli-input-json file://deployments/pipeline.json --region ca-central-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf12a82-33f2-448f-afe9-1179b7a3ca05",
   "metadata": {},
   "source": [
    "### 5. First Deployment\n",
    "#### 5.1 Trigger Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e89bbe-0bca-4333-ad82-90ffb092defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit an empty change to trigger\n",
    "git commit --allow-empty -m \"Initial pipeline trigger\"\n",
    "git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ee489-8b59-44f7-b1fd-ddcc59f2e9ac",
   "metadata": {},
   "source": [
    "#### 5.2 Verify Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f97a0-e53b-4e74-bd9d-6015221d33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ECS service URL\n",
    "aws elbv2 describe-load-balancers --query \"LoadBalancers[0].DNSName\" --output text\n",
    "\n",
    "# Test endpoint\n",
    "curl http://<DNS_NAME>:8080/health"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
