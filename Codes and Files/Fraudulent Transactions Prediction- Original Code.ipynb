{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4f443-b2cd-49ec-9d24-029e654cc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px  # Interactive plots (optional)\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# EDA & profiling\n",
    "\n",
    "# Interactive EDA\n",
    "# import pandasgui\n",
    "# from pandasgui import show\n",
    "# show(your_dataframe)  # Opens an interactive GUI\n",
    "\n",
    "# Auto-EDA\n",
    "# from dataprep.eda import create_report\n",
    "# create_report(your_dataframe).show()\n",
    "\n",
    "# Lightweight Profiling \n",
    "import sweetviz as sv\n",
    "# sv.analyze(your_dataframe).show_html()\n",
    "\n",
    "# from pandas_profiling import ProfileReport  # Auto-EDA (install: `pip install ydata-profiling`)\n",
    "import missingno as msno  # Missing data visualization (install: `pip install missingno`)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\",font_scale=1.5)\n",
    "pd.set_option(\"display.max.columns\",None)\n",
    "pd.set_option(\"display.max.rows\",None)\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress user warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # Suppress future warnings\n",
    "\n",
    "# Suppress specific warnings for LGBMClassifier and CatBoostClassifier\n",
    "import logging\n",
    "logging.getLogger(\"catboost\").setLevel(logging.ERROR)  # Suppress CatBoost logs\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)  # Suppress LightGBM logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1978e9c5-afa1-4b1d-a160-66bd51d4194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling/normalization\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    PowerTransformer,\n",
    "    label_binarize\n",
    ")\n",
    "\n",
    "# Splitting data\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Imputation (handling missing values)\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Outlier detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats  # For Z-score, IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb652159-5a68-480d-a945-8048e38e0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic ML\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,  # Faster alternative to CatBoost\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier  # Works on Python 3.13.2\n",
    "from lightgbm import LGBMClassifier  # Works on Python 3.13.2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Neural Networks (optional)\n",
    "# import tensorflow as tf  # or `pip install tensorflow-cpu`\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d48a6-0c4f-4501-98c7-09c6c52dc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    mean_squared_error,\n",
    "    roc_curve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6019752-e61a-4dce-811f-9ab4fb932ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Calibration\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Warnings (to clean output)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Time tracking\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bars (install: `pip install tqdm`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb5e2c6-222b-44e3-8147-65afa4995d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option(\"display.max_columns\", None)\n",
    "df = pd.read_csv(\"C:/Projects/Fraud Transaction Prediction/Fraud.csv\")# change this to your path\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50e116-1893-4bfa-8ea4-51a32f9fc4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Calibration\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Warnings (to clean output)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Time tracking\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bars (install: `pip install tqdm`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e33277-8f6f-4c04-a289-882511f60832",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f0cee-a8f1-439d-b23c-ed4cf2a767da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927b35f-5998-45f0-889f-604ffb2908b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f120e6-2896-4b7d-a5f1-3ce33d0bf536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3c649-6e6a-455b-8909-77bad4a398e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['step'].unique()\n",
    "print(unique_values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435233c-b1d0-469d-9309-51c727992eb9",
   "metadata": {},
   "source": [
    "#### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718cbdb8-82a9-48d1-b15b-b82b579eef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().to_frame().rename(columns={0:\"Total No. of Missing Values\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01856498-615f-4404-9ab6-a5c61570e43a",
   "metadata": {},
   "source": [
    "#### Checking for Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd9e8a-7334-41f0-bf51-3933f9687954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicate Values =\",df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343838a1-8857-4fed-97c7-d825e02c3705",
   "metadata": {},
   "source": [
    "#### Checking for numeric data columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8c50d-7349-47d3-8609-cec0649c4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = df.select_dtypes(include=[np.number])\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f5973-4e9f-4cca-a062-217b74dffa42",
   "metadata": {},
   "source": [
    "#### Checking for categorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198831b-a119-4ee9-91fc-08dea8acd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select_dtypes('object').columns \n",
    "# or you can use below\n",
    "categorical_data = df.select_dtypes(exclude=[np.number])\n",
    "categorical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50732e5c-5cd9-4197-9bbb-d0d075dfc3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation_matrix(df, size=8):\n",
    "    \"\"\"\n",
    "    Plots a correlation matrix for numeric columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df : pandas.DataFrame\n",
    "    size : int - Output figure size\n",
    "    \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Calculate correlations\n",
    "    corr = numeric_df.corr()\n",
    "    \n",
    "    # Set up the matplotlib figure\n",
    "    plt.figure(figsize=(size, size))\n",
    "    \n",
    "    # Generate a heatmap\n",
    "    sns.heatmap(corr, \n",
    "                annot=True, \n",
    "                fmt=\".2f\", \n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                square=True,\n",
    "                linewidths=.5)\n",
    "    \n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bee9e4-9fc8-4b14-86fc-76cb20c61c10",
   "metadata": {},
   "source": [
    "##### it looks like we have categorical data that we need to take care of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e626c-2a93-4a15-92ce-e25d2062acfb",
   "metadata": {},
   "source": [
    "### further exploration and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3ce40-f4dd-4893-b246-c5ed4b95ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrelationMatrix(df1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ffac8-9c9d-4e1a-8230-3c015ea7d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea6db0-f89d-4e8e-a886-e6a86059b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(numeric_data.corr(),text_auto=True,aspect=\"auto\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf5a61-e1f5-4524-b733-24fcfc320f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8277ca-8719-435a-9929-19cd1e5f4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3d1f5-5600-4950-b535-59d90ed2fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126baff3-eea0-433a-abeb-f671f628f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(15,10))\n",
    "plt.suptitle(\"Data Distribution\", fontsize=16)\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0233cf38-c597-4a02-b67b-f235c5bf290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='isFraud',data=df, palette='hls')\n",
    "plt.title(\"Imbalanced Fraud vs. Non-Fraud Distribution\", fontsize=14)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177de72-2a65-40f3-8006-58238e159c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = df[['isFraud', 'amount']].groupby(['isFraud']).count()\n",
    "ratio_df.plot.pie(y='amount', figsize=(5, 5), labels=['0: nonfraud', '1: fraud'], autopct='%.1f%%', startangle=120, wedgeprops={'width': 0.75},title = 'Imbalanced Fraud vs. Non-Fraud Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3fd10-aafc-4c2a-9613-a70a1f11990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot\n",
    "df.boxplot(column=[\"step\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"])\n",
    "plt.title(\"Box Plot Analysis\", fontsize=16)\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261560c8-7907-4176-8a9d-b263f6b6b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation test between the qualitative variable 'oldbalanceOrg' and the target variable\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1. Point-Biserial Correlation\n",
    "corr, p_value = stats.pointbiserialr(df['isFraud'], df['oldbalanceOrg'])\n",
    "print(f\"Point-Biserial Correlation: {corr:.3f} (p-value: {p_value:.3e})\")\n",
    "\n",
    "# 2. Welch's t-test (unequal variances)\n",
    "fraud_bal = df.loc[df['isFraud'] == 1, 'oldbalanceOrg']\n",
    "nonfraud_bal = df.loc[df['isFraud'] == 0, 'oldbalanceOrg']\n",
    "t_stat, p_val = stats.ttest_ind(fraud_bal, nonfraud_bal, equal_var=False)\n",
    "print(f\"t-test: Mean difference = {fraud_bal.mean() - nonfraud_bal.mean():.1f} (p-value: {p_val:.3e})\")\n",
    "\n",
    "# 3. AUC-ROC Evaluation\n",
    "auc = roc_auc_score(df['isFraud'], df['oldbalanceOrg'])\n",
    "print(f\"AUC: {auc:.3f} (0.5 = random, 1 = perfect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4638fae-6bb6-4e9c-8a4e-05bd662358d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test=stats.f_oneway(df['oldbalanceOrg'][df['isFraud']==1],df['oldbalanceOrg'][df['isFraud']==0])\n",
    "print(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cde359-1b76-4872-9d0f-9586dd9db804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='isFraud', y='oldbalanceOrg', data=df, showfliers=False)\n",
    "plt.yscale('log')  # Use if data is highly skewed\n",
    "plt.title(\"Distribution of oldbalanceOrg by Fraud Status\")\n",
    "plt.xlabel(\"Is Fraud? (0=No, 1=Yes)\")\n",
    "plt.ylabel(\"Original Balance (log scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdedc2-b1a2-42ce-b43a-9cc1288e823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze balance distribution for fraud vs non-fraud\n",
    "print(\"Fraudulent transactions balance percentiles:\")\n",
    "print(df[df['isFraud']==1]['oldbalanceOrg'].quantile([0.25, 0.5, 0.75, 0.9]))\n",
    "\n",
    "print(\"\\nNon-fraudulent transactions balance percentiles:\")\n",
    "print(df[df['isFraud']==0]['oldbalanceOrg'].quantile([0.25, 0.5, 0.75, 0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502f5cd-7059-425f-927c-1312ae5a7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles for fraud vs non-fraud transactions\n",
    "fraud_stats = df[df['isFraud']==1]['amount'].describe(percentiles=[.25, .5, .75, .9, .95, .99])\n",
    "nonfraud_stats = df[df['isFraud']==0]['amount'].describe(percentiles=[.25, .5, .75, .9, .95, .99])\n",
    "\n",
    "print(\"Fraudulent Transactions Amount Stats:\")\n",
    "print(fraud_stats[['min', '25%', '50%', '75%', '90%', '95%', '99%', 'max']])\n",
    "\n",
    "print(\"\\nNon-Fraudulent Transactions Amount Stats:\")\n",
    "print(nonfraud_stats[['min', '25%', '50%', '75%', '90%', '95%', '99%', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f5ec4-a8b3-42a7-9d88-e009fdeedee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_thresholds(df, feature, is_fraud, upper_percentile=0.95, lower_percentile=0.05):\n",
    "    \"\"\"Calculate thresholds based on percentiles of fraud/non-fraud data\"\"\"\n",
    "    fraud_vals = df[df['isFraud']==is_fraud][feature]\n",
    "    return {\n",
    "        'upper': fraud_vals.quantile(upper_percentile),\n",
    "        'lower': fraud_vals.quantile(lower_percentile),\n",
    "        'mean': fraud_vals.mean()\n",
    "    }\n",
    "\n",
    "# Example usage for amount\n",
    "amount_thresholds = {\n",
    "    'fraud': get_dynamic_thresholds(df, 'amount', is_fraud=1),\n",
    "    'nonfraud': get_dynamic_thresholds(df, 'amount', is_fraud=0)\n",
    "}\n",
    "print(\"\\nAmount Thresholds:\")\n",
    "print(amount_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40dc73-0023-428a-8a6e-ac7edaa0952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds based on 95th percentile of non-fraud (adjust as needed)\n",
    "high_amount_thresh = nonfraud_stats['95%']\n",
    "balance_change_thresh = df[df['isFraud']==0]['oldbalanceOrg'].quantile(0.9)\n",
    "\n",
    "# Engineered features with dynamic thresholds\n",
    "df['high_amount_flag'] = (df['amount'] > high_amount_thresh).astype(int)\n",
    "df['suspicious_balance_change'] = (\n",
    "    (df['oldbalanceOrg'] - df['newbalanceOrig']) > balance_change_thresh\n",
    ").astype(int)\n",
    "\n",
    "# Ratio-based feature with smoothing\n",
    "df['amount_to_balance_ratio'] = df['amount'] / (df['oldbalanceOrg'] + 1)  # +1 prevents divide-by-zero\n",
    "\n",
    "# Time-sensitive features (if 'step' is in hours)\n",
    "# Set thresholds based on 95th percentile of non-fraud (adjust as needed)\n",
    "high_amount_thresh = nonfraud_stats['95%']\n",
    "balance_change_thresh = df[df['isFraud']==0]['oldbalanceOrg'].quantile(0.9)\n",
    "\n",
    "# Engineered features with dynamic thresholds\n",
    "df['high_amount_flag'] = (df['amount'] > high_amount_thresh).astype(int)\n",
    "df['suspicious_balance_change'] = (\n",
    "    (df['oldbalanceOrg'] - df['newbalanceOrig']) > balance_change_thresh\n",
    ").astype(int)\n",
    "\n",
    "# Ratio-based feature with smoothing\n",
    "df['amount_to_balance_ratio'] = df['amount'] / (df['oldbalanceOrg'] + 1)  # +1 prevents divide-by-zero\n",
    "\n",
    "# # Time features \n",
    "# # Feature 1: Hour of day (1-24, where 1 = 00:00-00:59 of any day)\n",
    "# df['hour_of_day'] = ((df['step'] - 1) % 24) + 1  # Converts to 1-24 range\n",
    "\n",
    "# # Feature 2: Day of simulation (1-31, since 743 hours ≈ 30.96 days)\n",
    "# df['day'] = ((df['step'] - 1) // 24) + 1  # 1-based day count\n",
    "\n",
    "# # Feature 3: Day of week (0=Monday to 6=Sunday)\n",
    "# df['day_of_week'] = ((df['step'] - 1) // 24) % 7  # 0-based weekday\n",
    "\n",
    "# # Feature 4: Weekend flag (1 if Saturday/Sunday)\n",
    "# df['is_weekend'] = ((df['day_of_week'] == 5) | (df['day_of_week'] == 6)).astype(int)\n",
    "\n",
    "# # Feature 5: Transaction burst (1 if same user transacts again within 1 hour)\n",
    "# df['txn_burst'] = (df.groupby('nameOrig')['step'].diff() == 1).astype(int)\n",
    "\n",
    "# # Feature 6: Hours since last transaction (NaN for first txn per user)\n",
    "# df['hours_since_last_txn'] = df.groupby('nameOrig')['step'].diff()\n",
    "\n",
    "# # Feature 7: Transactions per user in last 24 hours (rolling window)\n",
    "# df['txn_count_24h'] = df.groupby('nameOrig')['step'].transform(\n",
    "#     lambda x: x.rolling(24, min_periods=1).count()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71aaa48-4325-4fba-9c55-abce6c010f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fraud rates in new features\n",
    "print(\"\\nFraud Rates by Engineered Features:\")\n",
    "print(df.groupby('high_amount_flag')['isFraud'].mean())\n",
    "print(df.groupby('suspicious_balance_change')['isFraud'].mean())\n",
    "\n",
    "# Visual confirmation\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "df.boxplot(column='amount_to_balance_ratio', by='isFraud', showfliers=False)\n",
    "plt.ylim(0, 5)  # Focus on 0-500% range\n",
    "plt.subplot(122)\n",
    "df.groupby('hour_of_day')['isFraud'].mean().plot()\n",
    "plt.title(\"Fraud Rate by Hour of Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c1ccf-0b0a-477c-bd75-38110ab6b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df, amount_percentile=0.95, balance_percentile=0.9):\n",
    "    \"\"\"Complete feature engineering with dynamic thresholds\"\"\"\n",
    "    # Calculate thresholds\n",
    "    amt_thresh = df[df['isFraud']==0]['amount'].quantile(amount_percentile)\n",
    "    bal_thresh = df[df['isFraud']==0]['oldbalanceOrg'].quantile(balance_percentile)\n",
    "    \n",
    "    # Transaction features\n",
    "    df['amount_to_balance'] = df['amount'] / (df['oldbalanceOrg'] + 1)\n",
    "    df['high_amount_flag'] = (df['amount'] > amt_thresh).astype(int)\n",
    "    \n",
    "    # Balance features\n",
    "    df['balance_change_abs'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
    "    df['balance_change_ratio'] = df['balance_change_abs'] / (df['oldbalanceOrg'] + 1)\n",
    "    df['suspicious_withdrawal'] = (\n",
    "        (df['balance_change_abs'] > bal_thresh) & \n",
    "        (df['amount_to_balance'] > 0.5)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Type-specific features\n",
    "    df['large_cashout'] = (\n",
    "        (df['type'] == 'CASH_OUT') & \n",
    "        (df['amount_to_balance'] > 0.7)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to your dataframe\n",
    "df = engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce36eb7-2c71-40ac-94fb-8d22a5363059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time features \n",
    "# Feature 1: Hour of day (1-24, where 1 = 00:00-00:59 of any day)\n",
    "df['hour_of_day'] = ((df['step'] - 1) % 24) + 1  # Converts to 1-24 range\n",
    "\n",
    "# Feature 2: Day of simulation (1-31, since 743 hours ≈ 30.96 days)\n",
    "df['day'] = ((df['step'] - 1) // 24) + 1  # 1-based day count\n",
    "\n",
    "# Feature 3: Day of week (0=Monday to 6=Sunday)\n",
    "df['day_of_week'] = ((df['step'] - 1) // 24) % 7  # 0-based weekday\n",
    "\n",
    "# Feature 4: Weekend flag (1 if Saturday/Sunday)\n",
    "df['is_weekend'] = ((df['day_of_week'] == 5) | (df['day_of_week'] == 6)).astype(int)\n",
    "\n",
    "# Feature 5: Transaction burst (1 if same user transacts again within 1 hour)\n",
    "df['txn_burst'] = (df.groupby('nameOrig')['step'].diff() == 1).astype(int)\n",
    "\n",
    "# Feature 6: Hours since last transaction (NaN for first txn per user)\n",
    "df['hours_since_last_txn'] = df.groupby('nameOrig')['step'].diff()\n",
    "\n",
    "# Feature 7: Transactions per user in last 24 hours (rolling window)\n",
    "df['txn_count_24h'] = df.groupby('nameOrig')['step'].transform(\n",
    "    lambda x: x.rolling(24, min_periods=1).count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b381ba-602d-4f19-831a-f65243d402a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754c3669-6fdb-40b0-a57c-d6604a0c892e",
   "metadata": {},
   "source": [
    "#### below features are just for exploration purposes, the purpose of this exercise is to learn run and keep it simple without going into extreme details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e629e619-06cc-486c-aea5-63fe9ecd83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature engineering\n",
    "# # Set threshold at 90th percentile of non-fraud transactions\n",
    "# balance_threshold = df[df['isFraud']==0]['oldbalanceOrg'].quantile(0.9)\n",
    "# txn_ratio_threshold = 0.5  # 50% of balance\n",
    "\n",
    "# df['high_risk_balance'] = (df['oldbalanceOrg'] > balance_threshold).astype(int)\n",
    "# df['suspicious_withdrawal'] = (\n",
    "#     (df['oldbalanceOrg'] > balance_threshold) & \n",
    "#     (df['amount'] > txn_ratio_threshold * df['oldbalanceOrg'])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e64aa7-cb9a-493b-882e-718c507fc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flag transactions in top 5% of amounts\n",
    "# amount_threshold = df['amount'].quantile(0.95)\n",
    "# df['large_txn_flag'] = (df['amount'] > amount_threshold).astype(int)\n",
    "\n",
    "# # Combined flag\n",
    "# df['high_risk_combo'] = (\n",
    "#     df['high_risk_balance'] | \n",
    "#     df['large_txn_flag']\n",
    "# ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597d84f5-0ff0-48cd-86d7-74e4fd350ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Engineering \n",
    "# # High-risk balance threshold (adjust based on quartiles)  \n",
    "# df['high_risk_balance'] = (df['oldbalanceOrg'] > 1_000_000).astype(int)  \n",
    "\n",
    "# # Interaction with transaction amount  \n",
    "# df['large_balance_large_txn'] = (df['oldbalanceOrg'] > 500_000) & (df['amount'] > 0.9 * df['oldbalanceOrg'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca33bb-fff1-48c6-a8d2-28073978dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of all features we created \n",
    "# engineered_features = [\n",
    "#     'high_risk_balance',\n",
    "#     'large_balance_large_txn', \n",
    "#     'large_txn_flag',\n",
    "#     'high_risk_combo',\n",
    "#     'suspicious_withdrawal'\n",
    "# ]\n",
    "\n",
    "# # Safely remove columns\n",
    "# df = df.drop(columns=[col for col in engineered_features if col in df.columns], errors='ignore')\n",
    "\n",
    "# # Verify removal\n",
    "# print(\"Current columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b395c4-c085-4e15-bbf5-d442bbb46c10",
   "metadata": {},
   "source": [
    "#### First: Encode Categorical Variables\n",
    "(Convert text → numbers before handling imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a44cf-5151-4a70-a183-8ce2425d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['type'], prefix='type') # handling the column 'type' first \n",
    "# Verify encoding\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2be48-96b2-477e-8f10-1d341ddf550f",
   "metadata": {},
   "source": [
    "#### Handling High-Cardinality ID Columns (nameOrig, nameDest)\n",
    "These columns appear to be transaction IDs (unique identifiers). Since they have extremely high cardinality (millions of unique values), do NOT one-hot encode them. Instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83e963-a9d4-4fa6-b82c-2c2e06ec74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['nameOrig', 'nameDest'], axis=1)  # Remove ID columns\n",
    "# Remove non-feature columns (including original categorical)\n",
    "X = df.drop(['isFraud', 'nameOrig', 'nameDest'], axis=1)\n",
    "y = df['isFraud']\n",
    "\n",
    "# Check all remaining features are numeric\n",
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e21436-dda7-4491-a2cc-bed9bc35a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample 100K rows for feature analysis\n",
    "sample_idx = np.random.choice(len(X), 100000, replace=False)\n",
    "X_sample = X.iloc[sample_idx]\n",
    "y_sample = y.iloc[sample_idx]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a33d4-e0db-4ec1-907f-31cb366fb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=30,       # Reduced from 50\n",
    "    max_depth=5,           # Shallower trees\n",
    "    min_samples_leaf=100,  # Larger leaf nodes\n",
    "    n_jobs=-1,             # Use all CPU cores\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X, y)  # Now runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4b6e3-2ff1-453d-8c29-8562b9c2e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster permutation importance (works with partial data)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(\n",
    "    rf, X_sample, y_sample,\n",
    "    n_repeats=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "plt.barh(X.columns[sorted_idx][:15], result.importances_mean[sorted_idx][:15])\n",
    "plt.title(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7b04c-960c-4a65-bc4f-e9cdc321d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf.fit(X, y)  # Now works with numeric-only data\n",
    "\n",
    "# Plot importance\n",
    "pd.Series(rf.feature_importances_, index=X.columns).nlargest(15).plot(kind='barh')\n",
    "plt.title(\"Top Predictive Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b5ac5-773d-4e83-b738-7a0000df266f",
   "metadata": {},
   "source": [
    "### Check if the data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb40cea-e3ef-4b27-bf5f-f3ee6d9f248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_count = df['isFraud'].value_counts()\n",
    "fraud_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c35b67-c347-4b77-a04b-d71c872351ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_percentage = df['isFraud'].value_counts(normalize=True) * 100\n",
    "fraud_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0fa8bb-ff46-4e47-a276-0f862143d5fb",
   "metadata": {},
   "source": [
    "#### it looks like the data is highly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b8f88f-d011-4c06-be70-57f6495f6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135334e0-d6f1-41d5-83c4-9e05ce33d67a",
   "metadata": {},
   "source": [
    "#### First, Split Your Data (Critical!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d992df-e5d4-4473-8307-232f7da42854",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['isFraud'], axis = 1)\n",
    "y = df['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41073c8d-ba93-4d16-ac15-aa5616178c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23e83bd-a1ab-4f45-91a1-ed2a0f76061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train - >  \",x_train.shape)\n",
    "print(\"y_train - >  \",y_train.shape)\n",
    "print(\"x_test  - >  \",x_test.shape)\n",
    "print(\"y_test  - >  \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ccf9e-a854-48a8-ada2-1e13f6d085a2",
   "metadata": {},
   "source": [
    "#### Scale/transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6581ae1-46c0-4cf9-a3fe-f30736233def",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4dff7-5c2f-4e5e-9914-9f1a4e71306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = pt.fit_transform(x_train)\n",
    "x_test_scaled = pt.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8040a-011a-4ab4-85eb-a9a9acbc5113",
   "metadata": {},
   "source": [
    "#### handle Imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd78fbc-d2e2-4300-95a5-d150ccc1e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = {}\n",
    "# for i in df.select_dtypes('object').columns:\n",
    "#     encoder[i] = LabelEncoder()\n",
    "#     df[i] = encoder[i].fit_transform(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6d812-34f0-4f52-aaad-1be640b5b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)  # 3:10 fraud/non-fraud ratio\n",
    "X_res, y_res = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "print(\"Resampled class counts:\", y_res.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c607e0-e84f-4729-8338-96c461ff414d",
   "metadata": {},
   "source": [
    "### Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099c2e1-db92-4f69-84c2-c5cc17f6e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, name):\n",
    "    \"\"\"Train and evaluate a single model, returning metrics and plots.\"\"\"\n",
    "    try:\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        # Metrics\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['Predicted Non-Fraud', 'Predicted Fraud'],\n",
    "                   yticklabels=['Actual Non-Fraud', 'Actual Fraud'])\n",
    "        plt.title(f'{name}\\nFP: {cm[0,1]} | FN: {cm[1,0]}')\n",
    "        plt.gca().add_patch(plt.Rectangle((1, 0), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "        plt.gca().add_patch(plt.Rectangle((0, 1), 1, 1, fill=False, edgecolor='orange', lw=2))\n",
    "        plt.show()\n",
    "        \n",
    "        # Return metrics\n",
    "        return {\n",
    "            'Model': name,\n",
    "            'Recall (Fraud)': report['1']['recall'],\n",
    "            'Precision (Fraud)': report['1']['precision'],\n",
    "            'F1 (Fraud)': report['1']['f1-score'],\n",
    "            'ROC AUC': roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "            'Type I (FP)': cm[0, 1],\n",
    "            'Type II (FN)': cm[1, 0]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed for {name}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a7b45-f8e3-4f19-a4e9-2c3ecf78dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []  \n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(\n",
    "    scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    tree_method='hist',  # Faster than exact\n",
    "    eval_metric='aucpr',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(xgb, X_res, y_res, x_test_scaled, y_test, \"XGBoost (Fast)\"))\n",
    "del xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309e927-d31a-4be3-8df5-cfe0a7f0282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    feature_fraction=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(lgbm, X_res, y_res, x_test_scaled, y_test, \"LightGBM\"))\n",
    "del lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123070ff-a5c1-4ea0-a20b-cff2f7c90b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest (Balanced)\n",
    "# ==============================================\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=50,\n",
    "    max_depth=7,\n",
    "    max_samples=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(rf, X_res, y_res, x_test_scaled, y_test, \"Random Forest\"))\n",
    "del rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f0853b-a61c-49a5-94dd-dacfacf9c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gradient Boosting (Lightweight)\n",
    "# ==============================================\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(gb, X_res, y_res, x_test_scaled, y_test, \"Gradient Boosting\"))\n",
    "del gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd1f9b-ae8f-4887-80ab-4dc7d028a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Logistic Regression (Fast)\n",
    "# ==============================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear',\n",
    "    penalty='l1',\n",
    "    max_iter=200,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(logreg, X_res, y_res, x_test_scaled, y_test, \"Logistic Reg\"))\n",
    "del logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1499a1b3-970b-4ecd-a99e-ab927c303f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Support Vector Classifier - SVC (Caution)\n",
    "# # ==============================================\n",
    "# from sklearn.svm import SVC\n",
    "# svc = SVC(\n",
    "#     class_weight='balanced',\n",
    "#     probability=True,\n",
    "#     kernel='rbf',\n",
    "#     gamma='scale',\n",
    "#     random_state=42,\n",
    "#     cache_size=1000  # Helps with memory\n",
    "# )\n",
    "# svc_results = evaluate_model(svc, X_res, y_res, x_test_scaled, y_test, \"SVC\")\n",
    "# if svc_results: results.append(svc_results)\n",
    "# del svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be4046-2738-41b9-bcd6-35f6b6bcea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. AdaBoost (Quick)\n",
    "# ==============================================\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(\n",
    "    n_estimators=50,\n",
    "    learning_rate=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(ada, X_res, y_res, x_test_scaled, y_test, \"AdaBoost\"))\n",
    "del ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747e313-d813-472c-9c78-fa71106d3ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et = ExtraTreesClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_estimators=50,\n",
    "    max_depth=7,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "results.append(evaluate_model(et, X_res, y_res, x_test_scaled, y_test, \"Extra Trees\"))\n",
    "del et"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531e329-5a34-4678-9835-75992111ee77",
   "metadata": {},
   "source": [
    "#### Combine and Rank Rsults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd4232-e34c-4361-a5af-117cba1d61de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame - THIS MUST COME AFTER ALL MODELS RUN\n",
    "results_df = pd.DataFrame([r for r in results if r is not None])\n",
    "\n",
    "# Rank models by fraud detection performance\n",
    "ranked_df = results_df.sort_values([\n",
    "    'Recall (Fraud)', \n",
    "    'F1 (Fraud)',\n",
    "    'Type II (FN)'\n",
    "], ascending=[False, False, True])\n",
    "\n",
    "# Add rank column\n",
    "ranked_df['Rank'] = range(1, len(ranked_df)+1)\n",
    "\n",
    "# Highlight top 3 models\n",
    "def highlight_top3(s):\n",
    "    top3 = s.nlargest(3).index\n",
    "    return ['background-color: #FFFF00' if i in top3 else '' for i in range(len(s))]\n",
    "\n",
    "ranked_df.style.apply(highlight_top3, subset=['Recall (Fraud)', 'F1 (Fraud)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
